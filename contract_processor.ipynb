{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contract Processor Notebook\n",
    "\n",
    "This notebook demonstrates the workflow for extracting structured data from a contract PDF using functions from `utils.py` and Google's Generative AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Import specific functions and exceptions from utils.py\n",
    "from utils import (\n",
    "    read_pdf, \n",
    "    build_llm_prompt, \n",
    "    parse_llm_response, \n",
    "    PDFReadError, \n",
    "    JSONParsingError, \n",
    "    LLMConfigurationError, \n",
    "    LLMGenerationError,\n",
    "    MODEL_NAME # Import the model name constant\n",
    ")\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set the path to your contract PDF and configure the Google Generative AI API key.\n",
    "\n",
    "**Important:** Replace `'YOUR_API_KEY'` with your actual key or load it securely (e.g., from environment variables using `os.getenv('GOOGLE_API_KEY')`). Also, update `contract_pdf_path` to point to your contract file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration --- \n",
    "contract_pdf_path = 'data/Acme Corp_Lore Agreement_Oct 2023.pdf' # <<< --- CHANGE THIS TO YOUR PDF PATH ---\n",
    "api_key = os.getenv('GOOGLE_API_KEY') # <<< --- LOAD FROM ENVIRONMENT VARIABLE (RECOMMENDED) ---\n",
    "\n",
    "# Or uncomment and set manually (less secure):\n",
    "# api_key = 'YOUR_API_KEY' \n",
    "\n",
    "if not api_key:\n",
    "    logging.warning(\"API key not found in environment variables. Please set GOOGLE_API_KEY or uncomment the manual assignment.\")\n",
    "    # Optionally raise an error or prompt the user\n",
    "    # raise ValueError(\"Google API Key is required.\")\n",
    "\n",
    "# Configure the generative AI client\n",
    "if api_key:\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        logging.info(\"Google Generative AI configured successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to configure Google Generative AI: {e}\")\n",
    "        # Raise a specific error for configuration issues\n",
    "        raise LLMConfigurationError(f\"Failed to configure Google Generative AI: {e}\") from e\n",
    "else:\n",
    "    logging.error(\"API Key not configured. Cannot proceed with LLM interaction.\")\n",
    "    # Handle missing API key appropriately for notebook execution\n",
    "    print(\"ERROR: Google API Key not configured. Please set it in the cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Contract PDF\n",
    "\n",
    "Use the `read_pdf` function from `utils.py` to extract text from the specified PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_text = None\n",
    "if os.path.exists(contract_pdf_path):\n",
    "    try:\n",
    "        logging.info(f\"Reading PDF: {contract_pdf_path}\")\n",
    "        contract_text = read_pdf(contract_pdf_path)\n",
    "        logging.info(f\"Successfully read {len(contract_text)} characters from the PDF.\")\n",
    "        # print(f\"Contract Text Snippet:\\n{contract_text[:500]}...\") # Uncomment to view snippet\n",
    "    except PDFReadError as e:\n",
    "        logging.error(f\"Error reading PDF: {e}\")\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred during PDF reading: {e}\", exc_info=True)\n",
    "        print(f\"An unexpected error occurred during PDF reading: {e}\")\n",
    "else:\n",
    "    logging.error(f\"PDF file not found at: {contract_pdf_path}\")\n",
    "    print(f\"Error: PDF file not found at '{contract_pdf_path}'. Please update the 'contract_pdf_path' variable in the configuration cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build LLM Prompt\n",
    "\n",
    "Use the `build_llm_prompt` function to construct the prompt containing the contract text and JSON instructions for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_prompt = None\n",
    "if contract_text:\n",
    "    try:\n",
    "        logging.info(\"Building LLM prompt...\")\n",
    "        llm_prompt = build_llm_prompt(contract_text)\n",
    "        logging.info(\"LLM prompt built successfully.\")\n",
    "        # print(f\"Prompt Snippet:\\n{llm_prompt[:500]}...\") # Uncomment to view snippet\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error building LLM prompt: {e}\", exc_info=True)\n",
    "        print(f\"An unexpected error occurred building the LLM prompt: {e}\")\n",
    "else:\n",
    "    logging.warning(\"Contract text not available. Cannot build LLM prompt.\")\n",
    "    print(\"Skipping prompt generation as contract text was not read.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Content with LLM\n",
    "\n",
    "Initialize the Generative Model and call it with the prompt to get the structured data response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response_text = None\n",
    "if llm_prompt and api_key: # Ensure prompt exists and API key is configured\n",
    "    try:\n",
    "        logging.info(f\"Initializing model: {MODEL_NAME}\")\n",
    "        model = genai.GenerativeModel(MODEL_NAME)\n",
    "        \n",
    "        logging.info(\"Sending request to the LLM...\")\n",
    "        # Consider adding generation_config for safety settings, temperature, etc.\n",
    "        # generation_config = genai.types.GenerationConfig(...) \n",
    "        response = model.generate_content(\n",
    "            llm_prompt, \n",
    "            # generation_config=generation_config\n",
    "        )\n",
    "        \n",
    "        # Check for safety ratings or blocks if necessary\n",
    "        # if response.prompt_feedback.block_reason:\n",
    "        #    logging.error(f\"Request blocked: {response.prompt_feedback.block_reason}\")\n",
    "        #    raise LLMGenerationError(f\"LLM request blocked: {response.prompt_feedback.block_reason}\")\n",
    "\n",
    "        llm_response_text = response.text\n",
    "        logging.info(\"LLM response received.\")\n",
    "        # print(f\"Raw LLM Response Snippet:\\n{llm_response_text[:500]}...\") # Uncomment to view\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during LLM content generation: {e}\", exc_info=True)\n",
    "        # Catch potential API errors, configuration errors etc.\n",
    "        print(f\"An error occurred interacting with the LLM: {e}\")\n",
    "        # Consider re-raising as LLMGenerationError or handling specific API exceptions\n",
    "        # raise LLMGenerationError(f\"LLM generation failed: {e}\") from e\n",
    "        \n",
    "elif not api_key:\n",
    "    logging.error(\"Cannot generate content: API key not configured.\")\n",
    "    print(\"Skipping LLM generation as API key is missing.\")\n",
    "else:\n",
    "    logging.warning(\"LLM prompt not available. Skipping LLM generation.\")\n",
    "    print(\"Skipping LLM generation as the prompt was not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parse LLM Response\n",
    "\n",
    "Use the `parse_llm_response` function to extract the clean JSON data from the raw text response provided by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = None\n",
    "if llm_response_text:\n",
    "    try:\n",
    "        logging.info(\"Parsing LLM response...\")\n",
    "        extracted_data = parse_llm_response(llm_response_text)\n",
    "        logging.info(\"LLM response parsed successfully.\")\n",
    "        \n",
    "        # --- Final Output --- \n",
    "        print(\"--- Extracted Contract Data (JSON) ---\")\n",
    "        print(json.dumps(extracted_data, indent=2))\n",
    "        print(\"--- End Extracted Data ---\")\n",
    "        \n",
    "    except JSONParsingError as e:\n",
    "        logging.error(f\"Failed to parse JSON from LLM response: {e}\")\n",
    "        print(f\"Error parsing JSON from LLM response: {e}\")\n",
    "        print(\"--- Raw LLM Response ---\")\n",
    "        print(llm_response_text)\n",
    "        print(\"--- End Raw Response ---\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred during response parsing: {e}\", exc_info=True)\n",
    "        print(f\"An unexpected error occurred during response parsing: {e}\")\n",
    "else:\n",
    "    logging.warning(\"LLM response text not available. Skipping parsing.\")\n",
    "    print(\"Skipping response parsing as no text was received from the LLM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Workflow Complete\n",
    "\n",
    "If successful, the `extracted_data` variable holds the final JSON structure parsed from the contract."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}